{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requisitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Copiando a pasta LabHdoop (material do professor) para o contexto do aluno\n",
    "url = 'https://drive.google.com/drive/folders/11-Os0P1Pzsniixmo0P91f9AnJcqJqtl0'\n",
    "gdown.download_folder(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Copiando a pasta LabHdoop (material do professor) para o contexto do aluno\n",
    "!source ./LabHdoop/colab_env.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Definindo as variáveis de ambiente do Hadoop\n",
    "os.environ['BASHRC_PATH'] = \"/root/.bashrc\"\n",
    "os.environ['HADOOP_CONFIG_DIR'] = \"./LabHdoop\"\n",
    "os.environ['HADOOP_BASE_DIR'] = \"./Hdoop\"\n",
    "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-11-openjdk-amd64\"  # readlink -f /usr/bin/javac\n",
    "os.environ['HADOOP_CLASSPATH'] = \"/usr/lib/jvm/java-11-openjdk-amd64/lib/tools.jar\"\n",
    "os.environ['HADOOP_HOME'] = \"./Hdoop/hadoop\"\n",
    "os.environ['HADOOP_INSTALL'] = \"./Hdoop\"\n",
    "os.environ['HADOOP_MAPRED_HOME'] = \"./Hdoop/hadoop\"\n",
    "os.environ['HADOOP_COMMON_HOME'] = \"./Hdoop/hadoop\"\n",
    "os.environ['HADOOP_HDFS_HOME'] = \"./Hdoop/hadoop\"\n",
    "os.environ['YARN_HOME'] = \"./Hdoop/hadoop\"\n",
    "os.environ['HADOOP_COMMON_LIB_NATIVE_DIR'] = \"./Hdoop/hadoop/lib/native\"\n",
    "os.environ['HADOOP_OPTS'] = \"-Djava.library.path=./Hdoop/hadoop/lib/native\"\n",
    "\n",
    "# Exibindo as variáveis de ambiente configuradas\n",
    "for var in [\n",
    "    'BASHRC_PATH', 'HADOOP_CONFIG_DIR', 'HADOOP_BASE_DIR', 'JAVA_HOME',\n",
    "    'HADOOP_CLASSPATH', 'HADOOP_HOME', 'HADOOP_INSTALL', 'HADOOP_MAPRED_HOME',\n",
    "    'HADOOP_COMMON_HOME', 'HADOOP_HDFS_HOME', 'YARN_HOME',\n",
    "    'HADOOP_COMMON_LIB_NATIVE_DIR', 'HADOOP_OPTS'\n",
    "]:\n",
    "    print(f\"{var} = {os.environ.get(var)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Criando o diretório onde os arquivos do Hadoop vão ser colocados\n",
    "!mkdir $HADOOP_BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Copiando os fonte do hadoop para a pasta $HADOOP_INSTALL_DIR\n",
    "!cp LabHdoop/hadoop-3.3.6.tar.gz $HADOOP_BASE_DIR\n",
    "# Opcionalmente pode-se recuperar os arquivos do hadoop pelo comando a seguir\n",
    "# !wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz -P $HADOOP_INSTALL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Descompactando os arquivos do hadoop na pasta $HADOOP_INSTALL_DIR\n",
    "!tar -xzvf $HADOOP_BASE_DIR/hadoop-3.3.6.tar.gz -C $HADOOP_BASE_DIR\n",
    "!mv $HADOOP_BASE_DIR/hadoop-3.3.6 $HADOOP_BASE_DIR/hadoop\n",
    "!rm $HADOOP_BASE_DIR/hadoop-3.3.6.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!ls -l $HADOOP_BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Setup do Hadoop (YARN) para funcionar em modo Single Node (Pseudo-Distribuído)\n",
    "!cp LabHdoop/hadoop-configs/hadoop-env.sh $HADOOP_HOME/etc/hadoop/\n",
    "!cp LabHdoop/hadoop-configs/core-site.xml $HADOOP_HOME/etc/hadoop/\n",
    "!cp LabHdoop/hadoop-configs/hdfs-site.xml $HADOOP_HOME/etc/hadoop/\n",
    "!cp LabHdoop/hadoop-configs/yarn-site.xml $HADOOP_HOME/etc/hadoop/\n",
    "!cp LabHdoop/hadoop-configs/mapred-site.xml $HADOOP_HOME/etc/hadoop/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Ajustando requisitos do Hadoop: ssh sem senha (passo 1)\n",
    "!rm -rf ~/.ssh\n",
    "!mkdir -p ~/.ssh\n",
    "!ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa\n",
    "# Ajustando requisitos do Hadoop: ssh sem senha (passo 2)\n",
    "!cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\n",
    "# Ajustando requisitos do Hadoop: ssh sem senha (passo 3)\n",
    "!chmod 0600 ~/.ssh/authorized_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Ajustando requisitos do Hadoop: install do pacote ssh server (passo 4)\n",
    "# Fazer no terminal com sudo\n",
    "!sudo apt update\n",
    "!sudo apt install -y openssh-server\n",
    "!sudo service ssh start\n",
    "\n",
    "# Testar se o service do ssh ta funcionando:\n",
    "!sudo service ssh status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!/etc/init.d/ssh start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!~/Desktop/labHadoop/Hdoop/hadoop/sbin/start-dfs.sh"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
